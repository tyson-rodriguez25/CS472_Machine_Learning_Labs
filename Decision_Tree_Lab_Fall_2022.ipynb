{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmRQru-LBIZH"
      },
      "source": [
        "# Decision Tree Lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "98eDdd6MBIZI"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "from scipy.io import arff\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import json\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dYCFSWpBIZJ"
      },
      "source": [
        "## 1. Implement the ID3 decision tree algorithm  \n",
        "- Use standard information gain as your basic attribute evaluation metric.  Note that ID3 would usually augment information gain with a mechanism to penalize statistically insignificant attribute splits to avoid overfit (e.g. early stopping, gain ratio, etc.)\n",
        "- Include the ability to handle unknown attributes by making \"unknown\" a separate output class.\n",
        "- You do not need to handle real valued attributes.\n",
        "- You are welcome to create other classes and/or functions in addition to the ones provided below. (e.g. If you build out a tree structure, you might create a node class).\n",
        "- It is a good idea to use simple data sets (like the lenses data and the pizza homework), which you can check by hand, to test each detailed step of your algorithm to make sure it works correctly. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GTuENyNYBIZJ"
      },
      "outputs": [],
      "source": [
        "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
        "\n",
        "    def __init__(self,counts=None):\n",
        "        \"\"\" Initialize class with chosen hyperparameters.\n",
        "        Args:\n",
        "        Optional Args (Args we think will make your life easier):\n",
        "            counts: A list of Ints that tell you how many types of each feature there are\n",
        "        Example:\n",
        "            DT  = DTClassifier()\n",
        "            or\n",
        "            DT = DTClassifier(count = [2,3,2,2])\n",
        "            Dataset = \n",
        "            [[0,1,0,0],\n",
        "            [1,2,1,1],\n",
        "            [0,1,1,0],\n",
        "            [1,2,0,1],\n",
        "            [0,0,1,1]]\n",
        "\n",
        "        \"\"\"\n",
        "        self.ig_splits = []\n",
        "        \n",
        "\n",
        "    def fit(self, x, y, Print=False):\n",
        "        \"\"\" Fit the data; Make the Decision tree\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 1D numpy array with the training targets\n",
        "\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "\n",
        "        \"\"\"\n",
        "        data = x.copy()\n",
        "        data[y.name] = y\n",
        "        self.tree = self.convert(self.decision_tree(data, data, x.columns, y.name, Print))\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict all classes for a dataset X\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "        \n",
        "        # convert input data into a dictionary of samples\n",
        "        samples = self.convert(X.to_dict(orient='records'))\n",
        "        \n",
        "        predictions = []\n",
        "        # make a prediction for every sample\n",
        "        for sample in samples:\n",
        "          predictions.append(self.make_prediction(sample, self.tree, 1.0))\n",
        "        return predictions\n",
        "\n",
        "    def entropy(self, attribute_column):\n",
        "        # find unique values and their frequency counts for the given attribute\n",
        "        values, counts = np.unique(attribute_column, return_counts=True)\n",
        "\n",
        "        # calculate entropy for each unique value\n",
        "        entropy_list = []\n",
        "\n",
        "        for i in range(len(values)):\n",
        "          probability = counts[i]/np.sum(counts)\n",
        "          entropy_list.append(-probability*np.log2(probability))\n",
        "\n",
        "        # calculate sum of individual entropy values\n",
        "        total_entropy = np.sum(entropy_list)\n",
        "\n",
        "        return total_entropy\n",
        "    \n",
        "    def information_gain(self, data, feature_attribute_name, target_attribute_name):\n",
        "        # find total entropy of given subset\n",
        "        total_entropy = self.entropy(data[target_attribute_name])\n",
        "\n",
        "        # find unique values and their frequency counts for the attribute to be split\n",
        "        values, counts = np.unique(data[feature_attribute_name], return_counts=True)\n",
        "\n",
        "        # calculate weighted entropy of subset\n",
        "        weighted_entropy_list = []\n",
        "\n",
        "        for i in range(len(values)):\n",
        "          subset_probability = counts[i]/np.sum(counts)\n",
        "          subset_entropy = self.entropy(data.where(data[feature_attribute_name]==values[i]).dropna()[target_attribute_name])\n",
        "          weighted_entropy_list.append(subset_probability*subset_entropy)\n",
        "\n",
        "        total_weighted_entropy = np.sum(weighted_entropy_list)\n",
        "\n",
        "        # calculate information gain\n",
        "        information_gain = total_entropy - total_weighted_entropy\n",
        "\n",
        "        return information_gain\n",
        "    \n",
        "    def decision_tree(self, data, orginal_data, feature_attribute_names, target_attribute_name,\n",
        "                      Print=False, depth=\"\", parent_node_class=None):\n",
        "        # base cases:\n",
        "        # if data is pure, return the majority class of subset\n",
        "        unique_classes = np.unique(data[target_attribute_name])\n",
        "        if len(unique_classes) <= 1:\n",
        "            if(Print):\n",
        "                print(f\"{depth}prediction = {unique_classes[0].decode()}\")\n",
        "            return unique_classes[0]\n",
        "        # if subset is empty, ie. no samples, return majority class of original data\n",
        "        elif len(data) == 0:\n",
        "          majority_class_index = np.argmax(np.unique(original_data[target_attribute_name], return_counts=True)[1])\n",
        "          return np.unique(original_data[target_attribute_name])[majority_class_index]\n",
        "        # if data set contains no features to train with, return parent node class\n",
        "        elif len(feature_attribute_names) == 0:\n",
        "          return parent_node_class\n",
        "        # if none of the above are true, construct a branch:\n",
        "        else:\n",
        "          # determine parent node class of current branch\n",
        "          majority_class_index = np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])\n",
        "          parent_node_class = unique_classes[majority_class_index]\n",
        "\n",
        "          # determine information gain values for each feature\n",
        "          # choose feature which best splits the data, ie. highest value\n",
        "          ig_values = [self.information_gain(data, feature, target_attribute_name) for feature in feature_attribute_names]\n",
        "          best_feature_index = np.argmax(ig_values)\n",
        "          self.ig_splits.append(ig_values[best_feature_index])\n",
        "          best_feature = feature_attribute_names[best_feature_index]\n",
        "            \n",
        "          # create tree structure, empty at first\n",
        "          tree = {best_feature: {}}\n",
        "\n",
        "          # remove best feature from available features, it will become the parent node\n",
        "          feature_attribute_names = [i for i in feature_attribute_names if i != best_feature]\n",
        "\n",
        "          # create nodes under parent node\n",
        "          parent_attribute_values = np.unique(data[best_feature])\n",
        "          for value in parent_attribute_values:\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "            if Print:\n",
        "                print(f\"{depth}{best_feature} = {value.decode()}\")\n",
        "            # call the algorithm recursively\n",
        "            subtree = self.decision_tree(sub_data, orginal_data, feature_attribute_names,\n",
        "                                         target_attribute_name, Print, depth+'    ', parent_node_class)\n",
        "\n",
        "            # add subtree to original tree\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "          return tree\n",
        "    \n",
        "    def make_prediction(self, sample, tree, default=1):\n",
        "        # map sample data to tree\n",
        "        for attribute in list(sample.keys()):\n",
        "          # check if feature exists in tree\n",
        "          if attribute in list(tree.keys()):\n",
        "            try:\n",
        "                result = tree[attribute][sample[attribute]]\n",
        "            except:\n",
        "                return default\n",
        "\n",
        "            result = tree[attribute][sample[attribute]]\n",
        "\n",
        "            # if more attributes exist within result, recursively find best result\n",
        "            if isinstance(result, dict):\n",
        "                return self.make_prediction(sample, result)\n",
        "            else:\n",
        "                return result\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 1D numpy array of the targets \n",
        "        \"\"\"\n",
        "        pred = self.predict(X)\n",
        "        y = np.array(self.convert(list(y)))\n",
        "        return np.mean(pred == y)\n",
        "    \n",
        "    def convert(self, data):\n",
        "        if isinstance(data, bytes):  return data.decode()\n",
        "        if isinstance(data, dict):   return dict(map(self.convert, data.items()))\n",
        "        if isinstance(data, tuple):  return tuple(map(self.convert, data))\n",
        "        if isinstance(data, list):   return list(map(self.convert, data))\n",
        "        return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCfoIJHlBIZK"
      },
      "source": [
        "### 1.1 (20%) Debug \n",
        "\n",
        "- Debug your model by training on the lenses dataset: [Debug Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses.arff)\n",
        "- Test your model on the lenses test set: [Debug Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses_test.arff)\n",
        "- Parameters:\n",
        "For this problem the number of unique feature values for each feature is: counts = [3,2,2,2] (You should compute this when you read in the data, before fitting)\n",
        "---\n",
        "\n",
        "Expected Results: Accuracy = [0.33]\n",
        "\n",
        "Information gain at splits = [0.5487949406953987, 0.7704260414863775, 0.3166890883150208, 1.0, 0.4591479170272447, 0.9182958340544894]\n",
        "\n",
        "Predictions should match this file: [Lenses Predictions](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv)\n",
        "\n",
        "*NOTE: The [Lenses Prediction](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv) uses the following encoding: soft=2, hard=0, none=1. Use this same encoding.*\n",
        "\n",
        "<!-- You should be able to get about 68% (61%-82%) predictive accuracy on the lenses data -->\n",
        "\n",
        "Here's what your decision tree splits and information gains should look like, with the corresponding child node predictions:\n",
        "\n",
        "<pre>\n",
        "tear_prod_rate = normal: 0.5487949406953987\n",
        "    astigmatism = no: 0.7704260414863775\n",
        "        age = pre_presbyopic: 0.3166890883150208\n",
        "            prediction: soft\n",
        "        age = presbyopic:\n",
        "            spectacle_prescrip = hypermetrope: 1.0\n",
        "                prediction: soft\n",
        "            spectacle_prescrip = myope:\n",
        "                prediction: none\n",
        "        age = young:\n",
        "            prediction: soft\n",
        "    astigmatism = yes:\n",
        "        spectacle_prescrip = hypermetrope: 0.4591479170272447\n",
        "            age = pre_presbyopic: 0.9182958340544894\n",
        "                prediction: none\n",
        "            age = presbyopic:\n",
        "                prediction: none\n",
        "            age = young:\n",
        "                prediction: hard\n",
        "        spectacle_prescrip = myope:\n",
        "            prediction: hard\n",
        "tear_prod_rate = reduced:\n",
        "    prediction: none\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kdx5kqZBIZK",
        "outputId": "9d7680cf-03d5-4f47-fe3b-f372b2b4f6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tear_prod_rate = normal\n",
            "    astigmatism = no\n",
            "        age = pre_presbyopic\n",
            "            prediction = soft\n",
            "        age = presbyopic\n",
            "            spectacle_prescrip = hypermetrope\n",
            "                prediction = soft\n",
            "            spectacle_prescrip = myope\n",
            "                prediction = none\n",
            "        age = young\n",
            "            prediction = soft\n",
            "    astigmatism = yes\n",
            "        spectacle_prescrip = hypermetrope\n",
            "            age = pre_presbyopic\n",
            "                prediction = none\n",
            "            age = presbyopic\n",
            "                prediction = none\n",
            "            age = young\n",
            "                prediction = hard\n",
            "        spectacle_prescrip = myope\n",
            "            prediction = hard\n",
            "tear_prod_rate = reduced\n",
            "    prediction = none\n",
            "[0.5487949406953982, 0.7704260414863778, 0.3166890883150208, 1.0, 0.4591479170272448, 0.9182958340544896]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.DataFrame(arff.loadarff('lenses.arff')[0], dtype=float)\n",
        "\n",
        "# Train Decision Tree\n",
        "x_train = data.drop(columns=\"contact_lenses\")\n",
        "y_train = data[\"contact_lenses\"]\n",
        "dt = DTClassifier()\n",
        "dt.fit(x_train, y_train, True)\n",
        "print(dt.ig_splits)\n",
        "\n",
        "# Load debug test data\n",
        "data = pd.DataFrame(arff.loadarff('lenses_test.arff')[0], dtype=float)\n",
        "\n",
        "# Predict and compute model accuracy\n",
        "x_test = data.drop(columns=\"contact_lenses\")\n",
        "y_test = data[\"contact_lenses\"]\n",
        "dt.score(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BBnfUvFBIZK"
      },
      "source": [
        "My accuracy and information gain at splits came out correctly and worked as expected as well as the tree splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ohjDyFYFBIZK"
      },
      "outputs": [],
      "source": [
        "# Optional Debugging Dataset - Pizza Homework\n",
        "# pizza_dataset = np.array([[1,2,0],[0,0,0],[0,1,1],[1,1,1],[1,0,0],[1,0,1],[0,2,1],[1,0,0],[0,2,0]])\n",
        "# pizza_labels = np.array([2,0,1,2,1,2,1,1,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VBCig2lBIZK"
      },
      "source": [
        "### 1.2 (20%) Evaluation \n",
        "\n",
        "- We will evaluate your model based on its performance on the zoo dataset. \n",
        "- Train your model using this dataset: [Evaluation Train Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo.arff)\n",
        "- Test your model on this dataset: [Evaluation Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo_test.arff)\n",
        "- Parameters: counts = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2] (You should compute this when you read in the data, before fitting)\n",
        "---\n",
        "Your progam should print out your accuracy on the evaluation test dataset and also the information gain of each split you make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0CnUR-eBIZL",
        "outputId": "309c9b4f-b08a-4131-9a67-c4a918e536d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "legs = 0\n",
            "    fins = F\n",
            "        toothed = F\n",
            "            prediction = c7\n",
            "        toothed = T\n",
            "            prediction = c3\n",
            "    fins = T\n",
            "        eggs = F\n",
            "            prediction = cT\n",
            "        eggs = T\n",
            "            prediction = c4\n",
            "legs = 2\n",
            "    hair = F\n",
            "        prediction = c2\n",
            "    hair = T\n",
            "        prediction = cT\n",
            "legs = 4\n",
            "    hair = F\n",
            "        predator = F\n",
            "            prediction = c3\n",
            "        predator = T\n",
            "            toothed = F\n",
            "                prediction = c7\n",
            "            toothed = T\n",
            "                prediction = c5\n",
            "    hair = T\n",
            "        prediction = cT\n",
            "legs = 5\n",
            "    prediction = c7\n",
            "legs = 6\n",
            "    predator = F\n",
            "        prediction = c6\n",
            "    predator = T\n",
            "        prediction = c7\n",
            "legs = 8\n",
            "    prediction = c7\n",
            "[1.3630469031539394, 0.8865408928220899, 0.9852281360342515, 0.6962122601251459, 0.8256265261578954, 0.6892019851173656, 0.8631205685666308, 0.7219280948873623, 0.7219280948873623]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.147"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Load evaluation training data\n",
        "data = pd.DataFrame(arff.loadarff('zoo.arff')[0])\n",
        "\n",
        "# Train Decision Tree\n",
        "x_train = data.drop(columns=\"type\")\n",
        "y_train = data[\"type\"]\n",
        "dt = DTClassifier()\n",
        "dt.fit(x_train, y_train, True)\n",
        "print(dt.ig_splits)\n",
        "\n",
        "# Load evaluation test data\n",
        "data = pd.DataFrame(arff.loadarff('zoo_test.arff')[0])\n",
        "\n",
        "# Predict and compute model accuracy\n",
        "x_test = data.drop(columns=\"type\")\n",
        "y_test = data[\"type\"]\n",
        "dt.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eNhSBzqBIZL"
      },
      "source": [
        "In the Zoo dataset, the information gain at the first split was very high at 1.36 the other splits after were not as high. The total model accuracy of the dataset was .147 which was about half of what we got from the lenses dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vif1UnarBIZL"
      },
      "source": [
        "## 2. Learn Cars and Voting Data Sets and Predict accuracy with *n*-fold CV  \n",
        "- Use your ID3 algorithm to induce decision trees for the cars dataset and the voting dataset.  Do not use a stopping criteria, but induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).\n",
        "- Implement and use 10-fold Cross Validation (CV) on each data set to predict how well the models will do on novel data.  \n",
        "- For each dataset, create a table with the training, validation, and test classification accuracy for each of the 10 runs and the average accuracies for the training, validation, and test data. \n",
        "- As a rough sanity check, typical decision tree accuracies for these data sets are: Cars: .90-.95, Vote: .92-.95."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLL1oh-GBIZL"
      },
      "source": [
        "### 2.1 (15%) Implement 10-fold Cross Validation and report results for the Cars Dataset\n",
        "- Use this [Cars Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff)\n",
        "- Create a table for your *n*-fold cross validation accuracies\n",
        "\n",
        "*If you are having trouble using scipy's loadarff function (scipy.io.arff.loadarff), try:*\n",
        "\n",
        "*pip install arff &nbsp;&nbsp;&nbsp;&nbsp;          # Install arff library*\n",
        "\n",
        "*import arff as arf*                   \n",
        "\n",
        "*cars = list(arf.load('cars.arff'))   &nbsp;&nbsp;&nbsp;&nbsp;# Load your downloaded dataset (!curl, etc.)*\n",
        "\n",
        "*df = pd.DataFrame(cars)*  \n",
        "\n",
        "*There may be additional cleaning needed*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCD-FVLtBIZL",
        "outputId": "8e0b4ec0-32b7-4f40-9a46-6a56475615aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8837209302325582\n",
            "0.9075144508670521\n",
            "0.8728323699421965\n",
            "0.8959537572254336\n",
            "0.884393063583815\n",
            "0.8837209302325582\n",
            "0.8786127167630058\n",
            "0.9075144508670521\n",
            "0.8901734104046243\n",
            "0.884393063583815\n",
            "average accuracy: 0.888882914370211\n",
            "safety = high\n",
            "    persons = 2\n",
            "        prediction = unacc\n",
            "    persons = 4\n",
            "        buying = high\n",
            "            maint = high\n",
            "                prediction = acc\n",
            "            maint = low\n",
            "                prediction = acc\n",
            "            maint = med\n",
            "                prediction = acc\n",
            "            maint = vhigh\n",
            "                prediction = unacc\n",
            "        buying = low\n",
            "            maint = high\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    prediction = acc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = good\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    prediction = good\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = good\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    prediction = good\n",
            "            maint = vhigh\n",
            "                prediction = acc\n",
            "        buying = med\n",
            "            maint = high\n",
            "                prediction = acc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = good\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    prediction = good\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    prediction = acc\n",
            "            maint = vhigh\n",
            "                prediction = acc\n",
            "        buying = vhigh\n",
            "            maint = high\n",
            "                prediction = unacc\n",
            "            maint = low\n",
            "                prediction = acc\n",
            "            maint = med\n",
            "                prediction = acc\n",
            "            maint = vhigh\n",
            "                prediction = unacc\n",
            "    persons = more\n",
            "        buying = high\n",
            "            maint = high\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = low\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = med\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = vhigh\n",
            "                prediction = unacc\n",
            "        buying = low\n",
            "            maint = high\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = vgood\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = good\n",
            "                    doors = 3\n",
            "                        prediction = vgood\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = good\n",
            "                    doors = 3\n",
            "                        prediction = vgood\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "            maint = vhigh\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "        buying = med\n",
            "            maint = high\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = good\n",
            "                    doors = 3\n",
            "                        prediction = vgood\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = vgood\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = vgood\n",
            "                    doors = 4\n",
            "                        prediction = vgood\n",
            "                    doors = 5more\n",
            "                        prediction = vgood\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "            maint = vhigh\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "        buying = vhigh\n",
            "            maint = high\n",
            "                prediction = unacc\n",
            "            maint = low\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = med\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = vhigh\n",
            "                prediction = unacc\n",
            "safety = low\n",
            "    prediction = unacc\n",
            "safety = med\n",
            "    persons = 2\n",
            "        prediction = unacc\n",
            "    persons = 4\n",
            "        buying = high\n",
            "            lug_boot = big\n",
            "                maint = high\n",
            "                    prediction = acc\n",
            "                maint = low\n",
            "                    prediction = acc\n",
            "                maint = med\n",
            "                    prediction = acc\n",
            "                maint = vhigh\n",
            "                    prediction = unacc\n",
            "            lug_boot = med\n",
            "                doors = 2\n",
            "                    prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = unacc\n",
            "                doors = 4\n",
            "                    maint = high\n",
            "                        prediction = acc\n",
            "                    maint = low\n",
            "                        prediction = acc\n",
            "                    maint = med\n",
            "                        prediction = acc\n",
            "                    maint = vhigh\n",
            "                        prediction = unacc\n",
            "                doors = 5more\n",
            "                    maint = high\n",
            "                        prediction = acc\n",
            "                    maint = low\n",
            "                        prediction = acc\n",
            "                    maint = med\n",
            "                        prediction = acc\n",
            "                    maint = vhigh\n",
            "                        prediction = unacc\n",
            "            lug_boot = small\n",
            "                prediction = unacc\n",
            "        buying = low\n",
            "            maint = high\n",
            "                prediction = acc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = good\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "                lug_boot = small\n",
            "                    prediction = acc\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = good\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "                lug_boot = small\n",
            "                    prediction = acc\n",
            "            maint = vhigh\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = unacc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "        buying = med\n",
            "            maint = high\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = unacc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = good\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "                lug_boot = small\n",
            "                    prediction = acc\n",
            "            maint = med\n",
            "                prediction = acc\n",
            "            maint = vhigh\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = unacc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "        buying = vhigh\n",
            "            maint = high\n",
            "                prediction = unacc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = unacc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = unacc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "            maint = vhigh\n",
            "                prediction = unacc\n",
            "    persons = more\n",
            "        buying = high\n",
            "            lug_boot = big\n",
            "                maint = high\n",
            "                    prediction = acc\n",
            "                maint = low\n",
            "                    prediction = acc\n",
            "                maint = med\n",
            "                    prediction = acc\n",
            "                maint = vhigh\n",
            "                    prediction = unacc\n",
            "            lug_boot = med\n",
            "                maint = high\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                maint = low\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                maint = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                maint = vhigh\n",
            "                    prediction = unacc\n",
            "            lug_boot = small\n",
            "                prediction = unacc\n",
            "        buying = low\n",
            "            maint = high\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = good\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = good\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "            maint = vhigh\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "        buying = med\n",
            "            maint = high\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = good\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = acc\n",
            "                    doors = 3\n",
            "                        prediction = good\n",
            "                    doors = 4\n",
            "                        prediction = good\n",
            "                    doors = 5more\n",
            "                        prediction = good\n",
            "                lug_boot = small\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "            maint = med\n",
            "                doors = 2\n",
            "                    lug_boot = big\n",
            "                        prediction = acc\n",
            "                    lug_boot = med\n",
            "                        prediction = acc\n",
            "                    lug_boot = small\n",
            "                        prediction = unacc\n",
            "                doors = 3\n",
            "                    prediction = acc\n",
            "                doors = 4\n",
            "                    prediction = acc\n",
            "                doors = 5more\n",
            "                    prediction = acc\n",
            "            maint = vhigh\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "        buying = vhigh\n",
            "            maint = high\n",
            "                prediction = unacc\n",
            "            maint = low\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "            maint = med\n",
            "                lug_boot = big\n",
            "                    prediction = acc\n",
            "                lug_boot = med\n",
            "                    doors = 2\n",
            "                        prediction = unacc\n",
            "                    doors = 3\n",
            "                        prediction = acc\n",
            "                    doors = 4\n",
            "                        prediction = acc\n",
            "                    doors = 5more\n",
            "                        prediction = acc\n",
            "                lug_boot = small\n",
            "                    prediction = unacc\n",
            "            maint = vhigh\n",
            "                prediction = unacc\n",
            "[0.26218435655426375, 0.4959051758564783, 0.49050742113130785, 0.8112781244591328, 0.8112781244591329, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.7987949406953985, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 1.0, 0.3850108412239499, 0.585675594806832, 0.18424289179001135, 0.9182958340544896, 0.18424289179001135, 0.9182958340544896, 0.18424289179001135, 0.9182958340544896, 0.7117953407445459, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.18424289179001135, 0.9182958340544896, 0.7478346445490028, 0.18424289179001135, 0.9182958340544896, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.18424289179001135, 0.9182958340544896, 0.7880764030341533, 0.18424289179001135, 0.9182958340544896, 0.18424289179001135, 0.9182958340544896, 0.3014215093944752, 0.26351151827197317, 0.3658632937969324, 0.8112781244591328, 0.5487949406953985, 0.8112781244591328, 0.8112781244591328, 0.5487949406953985, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.5487949406953985, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.31127812445913283, 0.6666666666666667, 1.0, 0.6666666666666667, 1.0, 0.22880689619082228, 0.38870689737262065, 0.8112781244591328, 0.38024081494414785, 0.8112781244591328, 0.8112781244591328, 0.8112781244591328, 0.4396550012954563, 0.18424289179001135, 0.9182958340544896, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.7094427151647752, 0.8112781244591328, 0.43072914156951847, 0.7094427151647752, 0.8112781244591328, 0.7398200465481319, 0.8112781244591328, 0.8112781244591328, 0.18424289179001135, 0.9182958340544896, 0.7094427151647752, 0.8112781244591328, 0.380930090909788, 0.7094427151647752, 0.8112781244591328, 0.7094427151647752, 0.8112781244591328]\n"
          ]
        }
      ],
      "source": [
        "def fold_i_of_k(dataset, i, k):\n",
        "    n = len(dataset)\n",
        "    return dataset[n*(i-1)//k:n*i//k]\n",
        "\n",
        "def k_fold_cross_validate(data, output_class, folds=3):\n",
        "    data = data.sample(frac=1).reset_index(drop=True)\n",
        "    data_set = []\n",
        "    scores = []\n",
        "    j = 0\n",
        "    for i in range(1, folds+1):\n",
        "        data_set.append(fold_i_of_k(data, i, folds))\n",
        "    for i in range(folds):\n",
        "        dfs_1 = data_set[0:i]\n",
        "        dfs_2 = data_set[i+1:len(data_set)+1]\n",
        "        df = dfs_1 + dfs_2\n",
        "        df = pd.concat(df)\n",
        "        x_train = df.drop(columns=output_class)\n",
        "        y_train = df[output_class]\n",
        "        x_test = data_set[i].drop(columns=output_class)\n",
        "        y_test = data_set[i][output_class]\n",
        "        dt = DTClassifier()\n",
        "        dt.fit(x_train, y_train)\n",
        "        score = dt.score(x_test, y_test)\n",
        "        print(score)\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "\n",
        "\n",
        "data = arff.loadarff('cars.arff')[0]\n",
        "df =  pd.DataFrame(data)\n",
        "scores = k_fold_cross_validate(df, \"class\", 10)\n",
        "print(f\"average accuracy: {np.mean(np.mean(scores))}\")\n",
        "cdt = dt.tree\n",
        "\n",
        "data = pd.DataFrame(arff.loadarff('cars.arff')[0])\n",
        "x_train = data.drop(columns=\"class\")\n",
        "y_train = data[\"class\"]\n",
        "dt = DTClassifier()\n",
        "dt.fit(x_train, y_train, True)\n",
        "print(dt.ig_splits)\n",
        "\n",
        "# Report Average Test Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGHh5YPgBIZM"
      },
      "source": [
        "My average accuracy for the 10 fold cross validation was about .88 or 88% with the cars dataset. My decision tree was .01 away from getting the typical. As stated above the accuracy should be .90 - .95."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVgmtuLWBIZM"
      },
      "source": [
        "### 2.3 (15%) Voting Dataset \n",
        "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)\n",
        "- Create a table for your *n*-fold cross validation accuracies\n",
        "- This data set has don't know data.  Discuss how your algorithm handles this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vt0EZDaBIZM",
        "outputId": "cc2aa9cd-095a-4447-a209-71169ce4091d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9302325581395349\n",
            "0.9090909090909091\n",
            "0.9534883720930233\n",
            "0.9318181818181818\n",
            "0.9767441860465116\n",
            "0.8863636363636364\n",
            "0.9302325581395349\n",
            "0.8863636363636364\n",
            "0.9767441860465116\n",
            "0.9772727272727273\n",
            "average accuracy: 0.9358350951374206\n",
            "physician-fee-freeze = ?\n",
            "    mx-missile = ?\n",
            "        prediction = republican\n",
            "    mx-missile = n\n",
            "        prediction = democrat\n",
            "    mx-missile = y\n",
            "        anti-satellite-test-ban = ?\n",
            "            prediction = democrat\n",
            "        anti-satellite-test-ban = n\n",
            "            prediction = republican\n",
            "        anti-satellite-test-ban = y\n",
            "            prediction = democrat\n",
            "physician-fee-freeze = n\n",
            "    adoption-of-the-budget-resolution = ?\n",
            "        prediction = democrat\n",
            "    adoption-of-the-budget-resolution = n\n",
            "        education-spending = ?\n",
            "            prediction = republican\n",
            "        education-spending = n\n",
            "            synfuels-corporation-cutback = n\n",
            "                religious-groups-in-schools = n\n",
            "                    crime = n\n",
            "                        prediction = democrat\n",
            "                    crime = y\n",
            "                        prediction = republican\n",
            "                religious-groups-in-schools = y\n",
            "                    prediction = democrat\n",
            "            synfuels-corporation-cutback = y\n",
            "                prediction = democrat\n",
            "        education-spending = y\n",
            "            prediction = democrat\n",
            "    adoption-of-the-budget-resolution = y\n",
            "        prediction = democrat\n",
            "physician-fee-freeze = y\n",
            "    synfuels-corporation-cutback = ?\n",
            "        prediction = republican\n",
            "    synfuels-corporation-cutback = n\n",
            "        duty-free-exports = ?\n",
            "            prediction = republican\n",
            "        duty-free-exports = n\n",
            "            adoption-of-the-budget-resolution = n\n",
            "                prediction = republican\n",
            "            adoption-of-the-budget-resolution = y\n",
            "                export-administration-act-south-africa = ?\n",
            "                    handicapped-infants = n\n",
            "                        prediction = democrat\n",
            "                    handicapped-infants = y\n",
            "                        prediction = republican\n",
            "                export-administration-act-south-africa = y\n",
            "                    prediction = republican\n",
            "        duty-free-exports = y\n",
            "            immigration = n\n",
            "                export-administration-act-south-africa = ?\n",
            "                    water-project-cost-sharing = n\n",
            "                        prediction = democrat\n",
            "                    water-project-cost-sharing = y\n",
            "                        prediction = republican\n",
            "                export-administration-act-south-africa = n\n",
            "                    prediction = republican\n",
            "                export-administration-act-south-africa = y\n",
            "                    prediction = democrat\n",
            "            immigration = y\n",
            "                prediction = republican\n",
            "    synfuels-corporation-cutback = y\n",
            "        adoption-of-the-budget-resolution = ?\n",
            "            prediction = democrat\n",
            "        adoption-of-the-budget-resolution = n\n",
            "            el-salvador-aid = n\n",
            "                prediction = democrat\n",
            "            el-salvador-aid = y\n",
            "                export-administration-act-south-africa = ?\n",
            "                    handicapped-infants = n\n",
            "                        prediction = republican\n",
            "                    handicapped-infants = y\n",
            "                        prediction = democrat\n",
            "                export-administration-act-south-africa = n\n",
            "                    superfund-right-to-sue = n\n",
            "                        prediction = democrat\n",
            "                    superfund-right-to-sue = y\n",
            "                        water-project-cost-sharing = n\n",
            "                            handicapped-infants = n\n",
            "                                prediction = democrat\n",
            "                            handicapped-infants = y\n",
            "                                prediction = republican\n",
            "                        water-project-cost-sharing = y\n",
            "                            prediction = republican\n",
            "                export-administration-act-south-africa = y\n",
            "                    prediction = republican\n",
            "        adoption-of-the-budget-resolution = y\n",
            "            anti-satellite-test-ban = n\n",
            "                prediction = democrat\n",
            "            anti-satellite-test-ban = y\n",
            "                prediction = republican\n",
            "[0.7400326561331952, 0.5172018025827264, 0.7219280948873623, 0.027190005630480824, 0.1942890872833824, 0.11340086418110334, 0.3219280948873623, 1.0, 0.11334212467921478, 0.03255461336288261, 0.02752743956649261, 0.2373974097831018, 1.0, 0.31168988698645606, 0.5, 1.0, 0.14682749388509952, 0.21515244081234708, 0.15142932630439743, 0.9182958340544896, 0.2935644431995963, 0.3059584928680418, 1.0, 0.9544340029249649]\n"
          ]
        }
      ],
      "source": [
        "data = arff.loadarff('voting_with_missing.arff')[0]\n",
        "df =  pd.DataFrame(data)\n",
        "df = df.replace(\"?\", \"unknown\")\n",
        "scores = k_fold_cross_validate(df, \"Class\", 10)\n",
        "print(f\"average accuracy: {np.mean(np.mean(scores))}\")\n",
        "\n",
        "data = pd.DataFrame(arff.loadarff('voting_with_missing.arff')[0])\n",
        "x_train = data.drop(columns=\"Class\")\n",
        "y_train = data[\"Class\"]\n",
        "dt = DTClassifier()\n",
        "dt.fit(x_train, y_train, True)\n",
        "print(dt.ig_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9sStr6nBIZM"
      },
      "source": [
        "For the 10 fold cross validation, the overall accuracy was about 94% or .94. Which is about the threshold it should be. It seems it did better on the voting datadet than it did with the cars dataset. Although there was one fold that got 1.0 as the test clasification accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EllcnwqzBIZM"
      },
      "source": [
        "### 2.4 (5%) Decision Tree Intuition\n",
        "- For each of the two problems above, summarize in English what the decision tree has learned (i.e. look at the induced tree and describe what \"rules\" it has discovered to try to solve each task). \n",
        "- If the tree is very large you can just discuss a few of the more shallow attribute combinations and the most important decisions made high in the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GYX7VseBIZM"
      },
      "source": [
        "In the Cars dataset, The Tree learned that the thing that most people want number 1 in a car is safety. It found that it best split with safety and then split at the amount of people it could hold. then it would split by buying and maintenence. It appears that safety is the one that people care about, in fact, that for a low safety rating, it automatically predicted that it was automatically in the \"unacc\" class.\n",
        "\n",
        "\n",
        "In the voting dataset, The tree leanred that depending on if they voted for physician fee freeze it could predic thier class more accuratly. For those who were unsure of a physician fee freeze the next split to determine was mx missile. If it was y on a physician fee freeze, the next split would be by synfuels corporate cutback. If it was n on the physician fee freeze, the next split would be adoption of the budget resolution. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiyxun1uBIZM"
      },
      "source": [
        "## 3 Using SciKit Learn's decision tree  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPDJOSAxBIZM"
      },
      "source": [
        "### 3.1 (10%) SK Learn on Voting Dataset\n",
        "- Use SciKit learns decision tree (CART) on the voting dataset and compare the results with your ID3 version. Use this [Voting Dataset with missing values].(https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)\n",
        "- Try different parameters and report what parameters perform the best on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "MNjpUL7-BIZN",
        "outputId": "3af7f292-827d-4ff4-f33b-5d34a5cabcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5ad7b368d6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             X, y = self._validate_data(\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             )\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'n'"
          ]
        }
      ],
      "source": [
        "def convert( data):\n",
        "    if isinstance(data, bytes):  return data.decode()\n",
        "    if isinstance(data, dict):   return dict(map(convert, data.items()))\n",
        "    if isinstance(data, tuple):  return tuple(map(convert, data))\n",
        "    if isinstance(data, list):   return list(map(convert, data))\n",
        "    return data\n",
        "data = arff.loadarff('voting_with_missing.arff')[0]\n",
        "data = convert(data)\n",
        "df =  pd.DataFrame(data, dtype=float)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "X = df.drop(columns=\"Class\").values\n",
        "y = df[\"Class\"].values\n",
        "X = np.array(convert(X.tolist()))\n",
        "y = np.array(convert(y.tolist()))\n",
        "\n",
        "clf = clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igyMxDlpBIZN"
      },
      "source": [
        "Discuss scikit CART results & also compare to your ID3 results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPDxEny5BIZN"
      },
      "source": [
        "### 3.2 (10%) Choose a data set of your choice (not already used in this or previous labs) and use the SK decision tree to learn it. Experiment with different hyper-parameters to try to get the best results possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "FznGWB-7BIZN",
        "outputId": "e3cff6b3-116a-4486-8af8-0aba705041ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-033e0a8fa881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tts' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e23kE5TrBIZN"
      },
      "source": [
        "Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNSw9mCIBIZN"
      },
      "source": [
        "### 3.3 (5%) Print sklearn's decision tree for your chosen data set (using export_graphviz or another tool) and discuss what you find. If your tree is too deep to reasonably fit on one page, show only the first several levels (e.g. top 5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "6fZ2qZNKBIZN",
        "outputId": "5693cfed-cded-4737-b884-bf5a686cff2c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-221bbb33a2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m t = tree.DecisionTreeClassifier(max_depth=depths[argm[0]],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 criterion=crit[argm[2]])\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'depths' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6edOJctBIZN"
      },
      "source": [
        "Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImCqsxM-BIZO"
      },
      "source": [
        "## 4. (Optional 5% extra credit) Implement reduced error pruning to help avoid overfitting\n",
        "- You will need to take a validation set out of your training data to do this, while still having a test set to test your final accuracy. \n",
        "- Create a table comparing your decision tree implementation's results on the cars and voting data sets with and without reduced error pruning. \n",
        "- This table should compare:\n",
        "    - a) The # of nodes (including leaf nodes) and tree depth of the final decision trees \n",
        "    - b) The generalization (test set) accuracy. (For the unpruned 10-fold CV models, just use their average values in the table)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqJe9P9ZBIZO"
      },
      "outputs": [],
      "source": [
        "# Reduced Error Pruning Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3aUGZ6qBIZO"
      },
      "source": [
        "Discussion"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf8c9878be96b81c1c8fce57c4415443b48baf3df3953f8cea607d661f4cb93b"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}